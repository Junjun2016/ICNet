2021-08-27 13:11:37,806 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: Tesla V100-SXM2-32GB
CUDA_HOME: /mnt/cache/share/polaris/dep/cuda-9.0-cudnn7.6.5
GCC: gcc (GCC) 5.4.0
PyTorch: 1.8.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.9.0+cu111
OpenCV: 4.5.3
MMCV: 1.3.11
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMSegmentation: 0.16.0+4ecbb3d
------------------------------------------------------------

2021-08-27 13:11:37,807 - mmseg - INFO - Distributed training: True
2021-08-27 13:11:38,055 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='ICNet',
        in_channels=3,
        layer_channels=(512, 2048),
        light_branch_middle_channels=32,
        psp_out_channels=512,
        out_channels=(64, 256, 256),
        resnet_cfg=dict(
            type='ResNetV1c',
            in_channels=3,
            depth=50,
            num_stages=4,
            out_indices=(0, 1, 2, 3),
            dilations=(1, 1, 2, 4),
            strides=(1, 2, 1, 1),
            norm_cfg=dict(type='SyncBN', requires_grad=True),
            norm_eval=False,
            style='pytorch',
            contract_dilation=True),
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False),
    decode_head=dict(
        type='ICHead',
        in_channels=(64, 256, 256),
        in_index=(0, 1, 2),
        input_transform='multiple_select',
        channels=128,
        dropout_ratio=0,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        num_classes=19,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 1024)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/train',
        ann_dir='gtFine/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 1024), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 1024), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=80000)
checkpoint_config = dict(by_epoch=False, interval=8000)
evaluation = dict(interval=8000, metric='mIoU', pre_eval=True)
work_dir = './work_dirs/icnet_r50-d8_512x1024_80k_cityscapes'
gpu_ids = range(0, 1)

2021-08-27 13:11:38,055 - mmseg - INFO - Set random seed to 0, deterministic: False
2021-08-27 13:11:42,755 - mmseg - INFO - initialize ICNet with init_cfg [{'type': 'Kaiming', 'mode': 'fan_out', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': '_BatchNorm'}, {'type': 'Normal', 'mean': 0.01, 'layer': 'Linear'}]
2021-08-27 13:11:47,507 - mmseg - INFO - initialize ResNetV1c with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2021-08-27 13:11:50,184 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:50,236 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:50,301 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:50,452 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:50,608 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:50,768 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:50,946 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:51,452 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:51,685 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:51,853 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:52,020 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:52,202 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:52,379 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:53,201 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:53,431 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:53,595 - mmseg - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2021-08-27 13:11:55,276 - mmseg - INFO - initialize PSPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
2021-08-27 13:11:57,430 - mmseg - INFO - initialize ICHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.backbone.stem.0.weight - torch.Size([32, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.stem.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stem.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stem.3.weight - torch.Size([32, 32, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.stem.4.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stem.4.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stem.6.weight - torch.Size([64, 32, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.stem.7.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.stem.7.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.0.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.1.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer1.2.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.0.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.1.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.2.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer2.3.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.0.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.1.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.2.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.3.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.4.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer3.5.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.0.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.1.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.backbone.layer4.2.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

backbone.backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.0.1.conv.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.psp_head.psp_modules.0.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.0.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.1.1.conv.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.psp_head.psp_modules.1.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.1.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.2.1.conv.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.psp_head.psp_modules.2.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.2.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.3.1.conv.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.psp_head.psp_modules.3.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.psp_modules.3.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.bottleneck.conv.weight - torch.Size([512, 4096, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.psp_head.bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.psp_head.bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub1.0.conv.weight - torch.Size([32, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv_sub1.0.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub1.0.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub1.1.conv.weight - torch.Size([32, 32, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv_sub1.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub1.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub1.2.conv.weight - torch.Size([64, 32, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv_sub1.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub1.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub2.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_sub2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub4.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv_sub4.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.conv_sub4.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([19, 128, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([19]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.cff_24.conv_low.conv.weight - torch.Size([128, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.cff_24.conv_low.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_24.conv_low.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_24.conv_high.conv.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.cff_24.conv_high.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_24.conv_high.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_24.conv_low_cls.weight - torch.Size([19, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_12.conv_low.conv.weight - torch.Size([128, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.cff_12.conv_low.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_12.conv_low.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_12.conv_high.conv.weight - torch.Size([128, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.cff_12.conv_high.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_12.conv_high.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cff_12.conv_low_cls.weight - torch.Size([19, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-08-27 13:11:57,664 - mmseg - INFO - EncoderDecoder(
  (backbone): ICNet(
    (backbone): ResNetV1c(
      (stem): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
      )
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)
      (layer1): ResLayer(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
      (layer2): ResLayer(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
      (layer3): ResLayer(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
      (layer4): ResLayer(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      )
    )
    init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
    (psp_head): PSPHead(
      input_transform=None, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss()
      (dropout): Dropout2d(p=0.1, inplace=False)
      (psp_modules): PPM(
        (0): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): ConvModule(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (1): Sequential(
          (0): AdaptiveAvgPool2d(output_size=2)
          (1): ConvModule(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (2): Sequential(
          (0): AdaptiveAvgPool2d(output_size=3)
          (1): ConvModule(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (3): Sequential(
          (0): AdaptiveAvgPool2d(output_size=6)
          (1): ConvModule(
            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
      (bottleneck): ConvModule(
        (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
    (conv_sub1): Sequential(
      (0): ConvModule(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (2): ConvModule(
        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_sub2): ConvModule(
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (conv_sub4): ConvModule(
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg=[{'type': 'Kaiming', 'mode': 'fan_out', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': '_BatchNorm'}, {'type': 'Normal', 'mean': 0.01, 'layer': 'Linear'}]
  (decode_head): ICHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))
    (cff_24): CascadeFeatureFusion(
      (conv_low): ConvModule(
        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (conv_high): ConvModule(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (conv_low_cls): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (cff_12): CascadeFeatureFusion(
      (conv_low): ConvModule(
        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (conv_high): ConvModule(
        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (conv_low_cls): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-08-27 13:11:57,752 - mmseg - INFO - Loaded 2975 images
2021-08-27 13:12:13,197 - mmseg - INFO - Loaded 500 images
2021-08-27 13:12:13,208 - mmseg - INFO - Start running, host: hejunjun@SH-IDC1-10-198-4-145, work_dir: /mnt/lustre/hejunjun/open-mmlab/icnet/work_dirs/icnet_r50-d8_512x1024_80k_cityscapes
2021-08-27 13:12:13,208 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-08-27 13:12:13,209 - mmseg - INFO - workflow: [('train', 1)], max: 80000 iters
2021-08-27 13:26:34,637 - mmseg - INFO - Iter [50/80000]	lr: 9.995e-03, eta: 20:04:30, time: 0.904, data_time: 0.139, memory: 18549, decode.final.loss_seg: 1.6894, decode.final.acc_seg: 42.9332, decode.4x.loss_seg: 0.6758, decode.4x.acc_seg: 42.9332, decode.cascade_1.loss_seg: 0.7805, decode.cascade_1.acc_seg: 37.3655, decode.cascade_2.loss_seg: 0.7644, decode.cascade_2.acc_seg: 39.7954, loss: 3.9100
2021-08-27 13:26:47,090 - mmseg - INFO - Iter [100/80000]	lr: 9.989e-03, eta: 12:48:32, time: 0.250, data_time: 0.011, memory: 18549, decode.final.loss_seg: 1.4007, decode.final.acc_seg: 51.8902, decode.4x.loss_seg: 0.5603, decode.4x.acc_seg: 51.8902, decode.cascade_1.loss_seg: 0.5935, decode.cascade_1.acc_seg: 50.0287, decode.cascade_2.loss_seg: 0.5928, decode.cascade_2.acc_seg: 50.0907, loss: 3.1472
2021-08-27 13:27:06,111 - mmseg - INFO - Iter [150/80000]	lr: 9.983e-03, eta: 11:20:30, time: 0.380, data_time: 0.038, memory: 18549, decode.final.loss_seg: 1.2164, decode.final.acc_seg: 56.8324, decode.4x.loss_seg: 0.4866, decode.4x.acc_seg: 56.8324, decode.cascade_1.loss_seg: 0.5071, decode.cascade_1.acc_seg: 55.7873, decode.cascade_2.loss_seg: 0.5117, decode.cascade_2.acc_seg: 55.2074, loss: 2.7219
2021-08-27 13:27:28,866 - mmseg - INFO - Iter [200/80000]	lr: 9.978e-03, eta: 11:01:27, time: 0.455, data_time: 0.094, memory: 18549, decode.final.loss_seg: 1.2439, decode.final.acc_seg: 55.6573, decode.4x.loss_seg: 0.4975, decode.4x.acc_seg: 55.6573, decode.cascade_1.loss_seg: 0.5118, decode.cascade_1.acc_seg: 55.5052, decode.cascade_2.loss_seg: 0.5152, decode.cascade_2.acc_seg: 55.3721, loss: 2.7684
2021-08-27 13:27:41,623 - mmseg - INFO - Iter [250/80000]	lr: 9.972e-03, eta: 9:56:52, time: 0.256, data_time: 0.013, memory: 18549, decode.final.loss_seg: 1.1967, decode.final.acc_seg: 59.6906, decode.4x.loss_seg: 0.4787, decode.4x.acc_seg: 59.6906, decode.cascade_1.loss_seg: 0.4950, decode.cascade_1.acc_seg: 59.2400, decode.cascade_2.loss_seg: 0.4999, decode.cascade_2.acc_seg: 59.2369, loss: 2.6703
2021-08-27 13:27:55,462 - mmseg - INFO - Iter [300/80000]	lr: 9.967e-03, eta: 9:18:14, time: 0.276, data_time: 0.013, memory: 18549, decode.final.loss_seg: 1.1449, decode.final.acc_seg: 57.9943, decode.4x.loss_seg: 0.4579, decode.4x.acc_seg: 57.9943, decode.cascade_1.loss_seg: 0.4599, decode.cascade_1.acc_seg: 58.6096, decode.cascade_2.loss_seg: 0.4628, decode.cascade_2.acc_seg: 58.3893, loss: 2.5255
2021-08-27 13:28:10,102 - mmseg - INFO - Iter [350/80000]	lr: 9.961e-03, eta: 8:53:42, time: 0.293, data_time: 0.011, memory: 18549, decode.final.loss_seg: 1.1251, decode.final.acc_seg: 59.2159, decode.4x.loss_seg: 0.4500, decode.4x.acc_seg: 59.2159, decode.cascade_1.loss_seg: 0.4530, decode.cascade_1.acc_seg: 59.7016, decode.cascade_2.loss_seg: 0.4569, decode.cascade_2.acc_seg: 59.6176, loss: 2.4851
2021-08-27 13:28:38,192 - mmseg - INFO - Iter [400/80000]	lr: 9.956e-03, eta: 9:19:18, time: 0.558, data_time: 0.051, memory: 18549, decode.final.loss_seg: 1.0430, decode.final.acc_seg: 63.2240, decode.4x.loss_seg: 0.4172, decode.4x.acc_seg: 63.2240, decode.cascade_1.loss_seg: 0.4182, decode.cascade_1.acc_seg: 63.3430, decode.cascade_2.loss_seg: 0.4223, decode.cascade_2.acc_seg: 63.1502, loss: 2.3007
2021-08-27 13:28:49,408 - mmseg - INFO - Iter [450/80000]	lr: 9.950e-03, eta: 8:50:26, time: 0.228, data_time: 0.013, memory: 18549, decode.final.loss_seg: 1.0166, decode.final.acc_seg: 62.6159, decode.4x.loss_seg: 0.4066, decode.4x.acc_seg: 62.6159, decode.cascade_1.loss_seg: 0.4117, decode.cascade_1.acc_seg: 63.0950, decode.cascade_2.loss_seg: 0.4187, decode.cascade_2.acc_seg: 62.5319, loss: 2.2537
2021-08-27 13:29:33,965 - mmseg - INFO - Iter [500/80000]	lr: 9.944e-03, eta: 9:55:05, time: 0.890, data_time: 0.130, memory: 18549, decode.final.loss_seg: 1.0240, decode.final.acc_seg: 63.2845, decode.4x.loss_seg: 0.4096, decode.4x.acc_seg: 63.2845, decode.cascade_1.loss_seg: 0.4102, decode.cascade_1.acc_seg: 63.7694, decode.cascade_2.loss_seg: 0.4159, decode.cascade_2.acc_seg: 63.3688, loss: 2.2597
2021-08-27 13:29:51,363 - mmseg - INFO - Iter [550/80000]	lr: 9.939e-03, eta: 9:42:29, time: 0.348, data_time: 0.037, memory: 18549, decode.final.loss_seg: 0.9659, decode.final.acc_seg: 65.6960, decode.4x.loss_seg: 0.3863, decode.4x.acc_seg: 65.6960, decode.cascade_1.loss_seg: 0.3960, decode.cascade_1.acc_seg: 65.6809, decode.cascade_2.loss_seg: 0.4024, decode.cascade_2.acc_seg: 65.3043, loss: 2.1507
2021-08-27 13:30:01,736 - mmseg - INFO - Iter [600/80000]	lr: 9.933e-03, eta: 9:16:36, time: 0.208, data_time: 0.035, memory: 18549, decode.final.loss_seg: 0.8887, decode.final.acc_seg: 67.6775, decode.4x.loss_seg: 0.3555, decode.4x.acc_seg: 67.6775, decode.cascade_1.loss_seg: 0.3691, decode.cascade_1.acc_seg: 67.4731, decode.cascade_2.loss_seg: 0.3759, decode.cascade_2.acc_seg: 67.0230, loss: 1.9891
2021-08-27 13:30:27,621 - mmseg - INFO - Iter [650/80000]	lr: 9.928e-03, eta: 9:25:55, time: 0.516, data_time: 0.057, memory: 18549, decode.final.loss_seg: 0.9512, decode.final.acc_seg: 64.1570, decode.4x.loss_seg: 0.3805, decode.4x.acc_seg: 64.1570, decode.cascade_1.loss_seg: 0.3904, decode.cascade_1.acc_seg: 63.9082, decode.cascade_2.loss_seg: 0.3963, decode.cascade_2.acc_seg: 63.3943, loss: 2.1183
2021-08-27 13:30:49,980 - mmseg - INFO - Iter [700/80000]	lr: 9.922e-03, eta: 9:27:25, time: 0.448, data_time: 0.044, memory: 18549, decode.final.loss_seg: 1.0072, decode.final.acc_seg: 63.1075, decode.4x.loss_seg: 0.4029, decode.4x.acc_seg: 63.1075, decode.cascade_1.loss_seg: 0.4128, decode.cascade_1.acc_seg: 63.0459, decode.cascade_2.loss_seg: 0.4179, decode.cascade_2.acc_seg: 62.7854, loss: 2.2409
2021-08-27 13:31:11,629 - mmseg - INFO - Iter [750/80000]	lr: 9.917e-03, eta: 9:27:24, time: 0.433, data_time: 0.089, memory: 18549, decode.final.loss_seg: 0.8991, decode.final.acc_seg: 66.3263, decode.4x.loss_seg: 0.3596, decode.4x.acc_seg: 66.3263, decode.cascade_1.loss_seg: 0.3728, decode.cascade_1.acc_seg: 65.8144, decode.cascade_2.loss_seg: 0.3790, decode.cascade_2.acc_seg: 65.2651, loss: 2.0105
2021-08-27 13:31:47,273 - mmseg - INFO - Iter [800/80000]	lr: 9.911e-03, eta: 9:50:17, time: 0.711, data_time: 0.214, memory: 18549, decode.final.loss_seg: 0.9275, decode.final.acc_seg: 65.4933, decode.4x.loss_seg: 0.3710, decode.4x.acc_seg: 65.4933, decode.cascade_1.loss_seg: 0.3792, decode.cascade_1.acc_seg: 65.8314, decode.cascade_2.loss_seg: 0.3849, decode.cascade_2.acc_seg: 65.4921, loss: 2.0626
2021-08-27 13:32:08,021 - mmseg - INFO - Iter [850/80000]	lr: 9.905e-03, eta: 9:47:27, time: 0.415, data_time: 0.066, memory: 18549, decode.final.loss_seg: 0.9018, decode.final.acc_seg: 67.5749, decode.4x.loss_seg: 0.3607, decode.4x.acc_seg: 67.5749, decode.cascade_1.loss_seg: 0.3675, decode.cascade_1.acc_seg: 67.5665, decode.cascade_2.loss_seg: 0.3751, decode.cascade_2.acc_seg: 66.9314, loss: 2.0051
2021-08-27 13:32:24,752 - mmseg - INFO - Iter [900/80000]	lr: 9.900e-03, eta: 9:39:03, time: 0.336, data_time: 0.030, memory: 18549, decode.final.loss_seg: 0.9034, decode.final.acc_seg: 65.8641, decode.4x.loss_seg: 0.3613, decode.4x.acc_seg: 65.8641, decode.cascade_1.loss_seg: 0.3728, decode.cascade_1.acc_seg: 65.6075, decode.cascade_2.loss_seg: 0.3801, decode.cascade_2.acc_seg: 65.1888, loss: 2.0176
2021-08-27 13:32:41,886 - mmseg - INFO - Iter [950/80000]	lr: 9.894e-03, eta: 9:31:59, time: 0.343, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.8355, decode.final.acc_seg: 69.2195, decode.4x.loss_seg: 0.3342, decode.4x.acc_seg: 69.2195, decode.cascade_1.loss_seg: 0.3491, decode.cascade_1.acc_seg: 68.5996, decode.cascade_2.loss_seg: 0.3563, decode.cascade_2.acc_seg: 68.1579, loss: 1.8751
2021-08-27 13:32:55,384 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 13:32:55,412 - mmseg - INFO - Iter [1000/80000]	lr: 9.889e-03, eta: 9:20:53, time: 0.271, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.8435, decode.final.acc_seg: 67.8841, decode.4x.loss_seg: 0.3374, decode.4x.acc_seg: 67.8841, decode.cascade_1.loss_seg: 0.3466, decode.cascade_1.acc_seg: 67.6049, decode.cascade_2.loss_seg: 0.3546, decode.cascade_2.acc_seg: 67.1130, loss: 1.8821
2021-08-27 13:33:13,256 - mmseg - INFO - Iter [1050/80000]	lr: 9.883e-03, eta: 9:15:26, time: 0.345, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.8279, decode.final.acc_seg: 68.6913, decode.4x.loss_seg: 0.3312, decode.4x.acc_seg: 68.6913, decode.cascade_1.loss_seg: 0.3435, decode.cascade_1.acc_seg: 68.2650, decode.cascade_2.loss_seg: 0.3503, decode.cascade_2.acc_seg: 67.8548, loss: 1.8528
2021-08-27 13:33:34,716 - mmseg - INFO - Iter [1100/80000]	lr: 9.878e-03, eta: 9:16:12, time: 0.441, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.8369, decode.final.acc_seg: 69.6367, decode.4x.loss_seg: 0.3347, decode.4x.acc_seg: 69.6367, decode.cascade_1.loss_seg: 0.3461, decode.cascade_1.acc_seg: 69.2487, decode.cascade_2.loss_seg: 0.3541, decode.cascade_2.acc_seg: 68.7339, loss: 1.8718
2021-08-27 13:34:05,338 - mmseg - INFO - Iter [1150/80000]	lr: 9.872e-03, eta: 9:26:00, time: 0.600, data_time: 0.034, memory: 18549, decode.final.loss_seg: 0.8215, decode.final.acc_seg: 68.7652, decode.4x.loss_seg: 0.3286, decode.4x.acc_seg: 68.7652, decode.cascade_1.loss_seg: 0.3397, decode.cascade_1.acc_seg: 68.5832, decode.cascade_2.loss_seg: 0.3480, decode.cascade_2.acc_seg: 68.0710, loss: 1.8378
2021-08-27 13:34:49,949 - mmseg - INFO - Iter [1200/80000]	lr: 9.866e-03, eta: 9:50:03, time: 0.877, data_time: 0.163, memory: 18549, decode.final.loss_seg: 0.8347, decode.final.acc_seg: 68.9509, decode.4x.loss_seg: 0.3339, decode.4x.acc_seg: 68.9509, decode.cascade_1.loss_seg: 0.3450, decode.cascade_1.acc_seg: 68.7596, decode.cascade_2.loss_seg: 0.3544, decode.cascade_2.acc_seg: 68.1634, loss: 1.8680
2021-08-27 13:35:11,595 - mmseg - INFO - Iter [1250/80000]	lr: 9.861e-03, eta: 9:50:09, time: 0.458, data_time: 0.096, memory: 18549, decode.final.loss_seg: 0.7640, decode.final.acc_seg: 70.5354, decode.4x.loss_seg: 0.3056, decode.4x.acc_seg: 70.5354, decode.cascade_1.loss_seg: 0.3145, decode.cascade_1.acc_seg: 70.5003, decode.cascade_2.loss_seg: 0.3229, decode.cascade_2.acc_seg: 69.9621, loss: 1.7069
2021-08-27 13:35:33,434 - mmseg - INFO - Iter [1300/80000]	lr: 9.855e-03, eta: 9:49:10, time: 0.437, data_time: 0.082, memory: 18549, decode.final.loss_seg: 0.7782, decode.final.acc_seg: 70.5406, decode.4x.loss_seg: 0.3113, decode.4x.acc_seg: 70.5406, decode.cascade_1.loss_seg: 0.3200, decode.cascade_1.acc_seg: 70.3675, decode.cascade_2.loss_seg: 0.3282, decode.cascade_2.acc_seg: 69.6929, loss: 1.7377
2021-08-27 13:35:49,601 - mmseg - INFO - Iter [1350/80000]	lr: 9.850e-03, eta: 9:42:43, time: 0.324, data_time: 0.007, memory: 18549, decode.final.loss_seg: 0.8202, decode.final.acc_seg: 70.4068, decode.4x.loss_seg: 0.3281, decode.4x.acc_seg: 70.4068, decode.cascade_1.loss_seg: 0.3389, decode.cascade_1.acc_seg: 70.0213, decode.cascade_2.loss_seg: 0.3472, decode.cascade_2.acc_seg: 69.4760, loss: 1.8344
2021-08-27 13:36:09,242 - mmseg - INFO - Iter [1400/80000]	lr: 9.844e-03, eta: 9:39:54, time: 0.392, data_time: 0.058, memory: 18549, decode.final.loss_seg: 0.7071, decode.final.acc_seg: 71.5369, decode.4x.loss_seg: 0.2828, decode.4x.acc_seg: 71.5369, decode.cascade_1.loss_seg: 0.2928, decode.cascade_1.acc_seg: 71.3752, decode.cascade_2.loss_seg: 0.3013, decode.cascade_2.acc_seg: 70.8353, loss: 1.5840
2021-08-27 13:36:31,242 - mmseg - INFO - Iter [1450/80000]	lr: 9.838e-03, eta: 9:39:21, time: 0.439, data_time: 0.067, memory: 18549, decode.final.loss_seg: 0.8453, decode.final.acc_seg: 68.6929, decode.4x.loss_seg: 0.3381, decode.4x.acc_seg: 68.6929, decode.cascade_1.loss_seg: 0.3476, decode.cascade_1.acc_seg: 68.3241, decode.cascade_2.loss_seg: 0.3560, decode.cascade_2.acc_seg: 67.8587, loss: 1.8871
2021-08-27 13:36:41,878 - mmseg - INFO - Iter [1500/80000]	lr: 9.833e-03, eta: 9:28:56, time: 0.212, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.7931, decode.final.acc_seg: 69.5201, decode.4x.loss_seg: 0.3173, decode.4x.acc_seg: 69.5201, decode.cascade_1.loss_seg: 0.3266, decode.cascade_1.acc_seg: 69.1078, decode.cascade_2.loss_seg: 0.3359, decode.cascade_2.acc_seg: 68.6614, loss: 1.7729
2021-08-27 13:36:58,032 - mmseg - INFO - Iter [1550/80000]	lr: 9.827e-03, eta: 9:23:57, time: 0.326, data_time: 0.014, memory: 18549, decode.final.loss_seg: 0.7464, decode.final.acc_seg: 71.5707, decode.4x.loss_seg: 0.2986, decode.4x.acc_seg: 71.5707, decode.cascade_1.loss_seg: 0.3085, decode.cascade_1.acc_seg: 71.1866, decode.cascade_2.loss_seg: 0.3182, decode.cascade_2.acc_seg: 70.6201, loss: 1.6717
2021-08-27 13:37:20,482 - mmseg - INFO - Iter [1600/80000]	lr: 9.822e-03, eta: 9:24:15, time: 0.447, data_time: 0.023, memory: 18549, decode.final.loss_seg: 0.7540, decode.final.acc_seg: 70.9380, decode.4x.loss_seg: 0.3016, decode.4x.acc_seg: 70.9380, decode.cascade_1.loss_seg: 0.3047, decode.cascade_1.acc_seg: 71.2199, decode.cascade_2.loss_seg: 0.3134, decode.cascade_2.acc_seg: 70.7056, loss: 1.6737
2021-08-27 13:37:39,649 - mmseg - INFO - Iter [1650/80000]	lr: 9.816e-03, eta: 9:21:59, time: 0.384, data_time: 0.012, memory: 18549, decode.final.loss_seg: 0.7183, decode.final.acc_seg: 73.0156, decode.4x.loss_seg: 0.2873, decode.4x.acc_seg: 73.0156, decode.cascade_1.loss_seg: 0.2967, decode.cascade_1.acc_seg: 72.5992, decode.cascade_2.loss_seg: 0.3057, decode.cascade_2.acc_seg: 72.0076, loss: 1.6081
2021-08-27 13:38:05,206 - mmseg - INFO - Iter [1700/80000]	lr: 9.811e-03, eta: 9:24:28, time: 0.504, data_time: 0.037, memory: 18549, decode.final.loss_seg: 0.7355, decode.final.acc_seg: 72.1600, decode.4x.loss_seg: 0.2942, decode.4x.acc_seg: 72.1600, decode.cascade_1.loss_seg: 0.3037, decode.cascade_1.acc_seg: 71.8905, decode.cascade_2.loss_seg: 0.3130, decode.cascade_2.acc_seg: 71.3166, loss: 1.6465
2021-08-27 13:38:25,106 - mmseg - INFO - Iter [1750/80000]	lr: 9.805e-03, eta: 9:23:08, time: 0.406, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.6849, decode.final.acc_seg: 73.6430, decode.4x.loss_seg: 0.2740, decode.4x.acc_seg: 73.6430, decode.cascade_1.loss_seg: 0.2864, decode.cascade_1.acc_seg: 73.2103, decode.cascade_2.loss_seg: 0.2952, decode.cascade_2.acc_seg: 72.6253, loss: 1.5404
2021-08-27 13:38:43,386 - mmseg - INFO - Iter [1800/80000]	lr: 9.799e-03, eta: 9:20:20, time: 0.364, data_time: 0.039, memory: 18549, decode.final.loss_seg: 0.7310, decode.final.acc_seg: 71.8420, decode.4x.loss_seg: 0.2924, decode.4x.acc_seg: 71.8420, decode.cascade_1.loss_seg: 0.2960, decode.cascade_1.acc_seg: 72.0449, decode.cascade_2.loss_seg: 0.3037, decode.cascade_2.acc_seg: 71.5289, loss: 1.6232
2021-08-27 13:38:59,071 - mmseg - INFO - Iter [1850/80000]	lr: 9.794e-03, eta: 9:15:53, time: 0.314, data_time: 0.018, memory: 18549, decode.final.loss_seg: 0.6988, decode.final.acc_seg: 72.2441, decode.4x.loss_seg: 0.2795, decode.4x.acc_seg: 72.2441, decode.cascade_1.loss_seg: 0.2889, decode.cascade_1.acc_seg: 72.0760, decode.cascade_2.loss_seg: 0.2986, decode.cascade_2.acc_seg: 71.3985, loss: 1.5658
2021-08-27 13:39:11,785 - mmseg - INFO - Iter [1900/80000]	lr: 9.788e-03, eta: 9:09:36, time: 0.254, data_time: 0.022, memory: 18549, decode.final.loss_seg: 0.7413, decode.final.acc_seg: 72.1791, decode.4x.loss_seg: 0.2965, decode.4x.acc_seg: 72.1791, decode.cascade_1.loss_seg: 0.3037, decode.cascade_1.acc_seg: 72.1150, decode.cascade_2.loss_seg: 0.3112, decode.cascade_2.acc_seg: 71.6607, loss: 1.6527
2021-08-27 13:39:55,773 - mmseg - INFO - Iter [1950/80000]	lr: 9.783e-03, eta: 9:24:27, time: 0.878, data_time: 0.057, memory: 18549, decode.final.loss_seg: 0.7337, decode.final.acc_seg: 71.9506, decode.4x.loss_seg: 0.2935, decode.4x.acc_seg: 71.9506, decode.cascade_1.loss_seg: 0.3006, decode.cascade_1.acc_seg: 71.7117, decode.cascade_2.loss_seg: 0.3095, decode.cascade_2.acc_seg: 71.1635, loss: 1.6373
2021-08-27 13:40:07,142 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 13:40:07,142 - mmseg - INFO - Iter [2000/80000]	lr: 9.777e-03, eta: 9:17:30, time: 0.231, data_time: 0.011, memory: 18549, decode.final.loss_seg: 0.7227, decode.final.acc_seg: 71.4496, decode.4x.loss_seg: 0.2891, decode.4x.acc_seg: 71.4496, decode.cascade_1.loss_seg: 0.2994, decode.cascade_1.acc_seg: 71.1288, decode.cascade_2.loss_seg: 0.3084, decode.cascade_2.acc_seg: 70.4364, loss: 1.6196
2021-08-27 13:40:20,031 - mmseg - INFO - Iter [2050/80000]	lr: 9.771e-03, eta: 9:11:37, time: 0.255, data_time: 0.019, memory: 18549, decode.final.loss_seg: 0.7282, decode.final.acc_seg: 72.1286, decode.4x.loss_seg: 0.2913, decode.4x.acc_seg: 72.1286, decode.cascade_1.loss_seg: 0.2993, decode.cascade_1.acc_seg: 71.7126, decode.cascade_2.loss_seg: 0.3090, decode.cascade_2.acc_seg: 71.0942, loss: 1.6277
2021-08-27 13:40:30,406 - mmseg - INFO - Iter [2100/80000]	lr: 9.766e-03, eta: 9:04:39, time: 0.210, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.6808, decode.final.acc_seg: 74.1230, decode.4x.loss_seg: 0.2723, decode.4x.acc_seg: 74.1230, decode.cascade_1.loss_seg: 0.2831, decode.cascade_1.acc_seg: 73.8863, decode.cascade_2.loss_seg: 0.2929, decode.cascade_2.acc_seg: 73.2786, loss: 1.5291
2021-08-27 13:40:43,239 - mmseg - INFO - Iter [2150/80000]	lr: 9.760e-03, eta: 8:59:21, time: 0.256, data_time: 0.011, memory: 18549, decode.final.loss_seg: 0.6892, decode.final.acc_seg: 72.8848, decode.4x.loss_seg: 0.2757, decode.4x.acc_seg: 72.8848, decode.cascade_1.loss_seg: 0.2854, decode.cascade_1.acc_seg: 72.7085, decode.cascade_2.loss_seg: 0.2953, decode.cascade_2.acc_seg: 72.0294, loss: 1.5455
2021-08-27 13:41:12,609 - mmseg - INFO - Iter [2200/80000]	lr: 9.755e-03, eta: 9:04:04, time: 0.588, data_time: 0.096, memory: 18549, decode.final.loss_seg: 0.6609, decode.final.acc_seg: 73.2571, decode.4x.loss_seg: 0.2644, decode.4x.acc_seg: 73.2571, decode.cascade_1.loss_seg: 0.2770, decode.cascade_1.acc_seg: 72.8250, decode.cascade_2.loss_seg: 0.2870, decode.cascade_2.acc_seg: 72.2238, loss: 1.4893
2021-08-27 13:41:33,787 - mmseg - INFO - Iter [2250/80000]	lr: 9.749e-03, eta: 9:03:49, time: 0.423, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.6689, decode.final.acc_seg: 73.5142, decode.4x.loss_seg: 0.2676, decode.4x.acc_seg: 73.5142, decode.cascade_1.loss_seg: 0.2752, decode.cascade_1.acc_seg: 73.5449, decode.cascade_2.loss_seg: 0.2861, decode.cascade_2.acc_seg: 72.9273, loss: 1.4977
2021-08-27 13:41:44,291 - mmseg - INFO - Iter [2300/80000]	lr: 9.744e-03, eta: 8:57:34, time: 0.210, data_time: 0.015, memory: 18549, decode.final.loss_seg: 0.6503, decode.final.acc_seg: 75.0448, decode.4x.loss_seg: 0.2601, decode.4x.acc_seg: 75.0448, decode.cascade_1.loss_seg: 0.2709, decode.cascade_1.acc_seg: 74.5550, decode.cascade_2.loss_seg: 0.2805, decode.cascade_2.acc_seg: 73.9457, loss: 1.4617
2021-08-27 13:41:54,757 - mmseg - INFO - Iter [2350/80000]	lr: 9.738e-03, eta: 8:51:35, time: 0.210, data_time: 0.013, memory: 18549, decode.final.loss_seg: 0.6703, decode.final.acc_seg: 72.7012, decode.4x.loss_seg: 0.2681, decode.4x.acc_seg: 72.7012, decode.cascade_1.loss_seg: 0.2760, decode.cascade_1.acc_seg: 72.5443, decode.cascade_2.loss_seg: 0.2847, decode.cascade_2.acc_seg: 72.1082, loss: 1.4991
2021-08-27 13:42:12,173 - mmseg - INFO - Iter [2400/80000]	lr: 9.732e-03, eta: 8:49:32, time: 0.347, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.6440, decode.final.acc_seg: 74.4281, decode.4x.loss_seg: 0.2576, decode.4x.acc_seg: 74.4281, decode.cascade_1.loss_seg: 0.2681, decode.cascade_1.acc_seg: 73.9684, decode.cascade_2.loss_seg: 0.2775, decode.cascade_2.acc_seg: 73.2856, loss: 1.4472
2021-08-27 13:42:23,056 - mmseg - INFO - Iter [2450/80000]	lr: 9.727e-03, eta: 8:43:53, time: 0.208, data_time: 0.012, memory: 18549, decode.final.loss_seg: 0.6331, decode.final.acc_seg: 74.0973, decode.4x.loss_seg: 0.2533, decode.4x.acc_seg: 74.0973, decode.cascade_1.loss_seg: 0.2652, decode.cascade_1.acc_seg: 73.6914, decode.cascade_2.loss_seg: 0.2747, decode.cascade_2.acc_seg: 73.0160, loss: 1.4264
2021-08-27 13:42:46,787 - mmseg - INFO - Iter [2500/80000]	lr: 9.721e-03, eta: 8:45:33, time: 0.483, data_time: 0.097, memory: 18549, decode.final.loss_seg: 0.6709, decode.final.acc_seg: 73.8629, decode.4x.loss_seg: 0.2684, decode.4x.acc_seg: 73.8629, decode.cascade_1.loss_seg: 0.2786, decode.cascade_1.acc_seg: 73.4372, decode.cascade_2.loss_seg: 0.2885, decode.cascade_2.acc_seg: 72.7866, loss: 1.5064
2021-08-27 13:43:04,522 - mmseg - INFO - Iter [2550/80000]	lr: 9.716e-03, eta: 8:43:58, time: 0.358, data_time: 0.025, memory: 18549, decode.final.loss_seg: 0.6555, decode.final.acc_seg: 72.8814, decode.4x.loss_seg: 0.2622, decode.4x.acc_seg: 72.8814, decode.cascade_1.loss_seg: 0.2715, decode.cascade_1.acc_seg: 72.6243, decode.cascade_2.loss_seg: 0.2831, decode.cascade_2.acc_seg: 71.9063, loss: 1.4722
2021-08-27 13:43:26,864 - mmseg - INFO - Iter [2600/80000]	lr: 9.710e-03, eta: 8:44:35, time: 0.445, data_time: 0.045, memory: 18549, decode.final.loss_seg: 0.6295, decode.final.acc_seg: 75.1442, decode.4x.loss_seg: 0.2518, decode.4x.acc_seg: 75.1442, decode.cascade_1.loss_seg: 0.2606, decode.cascade_1.acc_seg: 74.8593, decode.cascade_2.loss_seg: 0.2695, decode.cascade_2.acc_seg: 74.2970, loss: 1.4114
2021-08-27 13:43:57,690 - mmseg - INFO - Iter [2650/80000]	lr: 9.704e-03, eta: 8:49:22, time: 0.618, data_time: 0.069, memory: 18549, decode.final.loss_seg: 0.6797, decode.final.acc_seg: 74.4343, decode.4x.loss_seg: 0.2719, decode.4x.acc_seg: 74.4343, decode.cascade_1.loss_seg: 0.2798, decode.cascade_1.acc_seg: 74.1442, decode.cascade_2.loss_seg: 0.2899, decode.cascade_2.acc_seg: 73.6017, loss: 1.5213
2021-08-27 13:44:08,413 - mmseg - INFO - Iter [2700/80000]	lr: 9.699e-03, eta: 8:44:14, time: 0.210, data_time: 0.009, memory: 18549, decode.final.loss_seg: 0.6161, decode.final.acc_seg: 74.2716, decode.4x.loss_seg: 0.2464, decode.4x.acc_seg: 74.2716, decode.cascade_1.loss_seg: 0.2562, decode.cascade_1.acc_seg: 73.9960, decode.cascade_2.loss_seg: 0.2665, decode.cascade_2.acc_seg: 73.3851, loss: 1.3853
2021-08-27 13:44:29,566 - mmseg - INFO - Iter [2750/80000]	lr: 9.693e-03, eta: 8:44:21, time: 0.426, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.6757, decode.final.acc_seg: 73.3882, decode.4x.loss_seg: 0.2703, decode.4x.acc_seg: 73.3882, decode.cascade_1.loss_seg: 0.2781, decode.cascade_1.acc_seg: 72.9355, decode.cascade_2.loss_seg: 0.2869, decode.cascade_2.acc_seg: 72.4586, loss: 1.5111
2021-08-27 13:44:44,483 - mmseg - INFO - Iter [2800/80000]	lr: 9.688e-03, eta: 8:41:32, time: 0.299, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.7086, decode.final.acc_seg: 72.6931, decode.4x.loss_seg: 0.2835, decode.4x.acc_seg: 72.6931, decode.cascade_1.loss_seg: 0.2878, decode.cascade_1.acc_seg: 72.5472, decode.cascade_2.loss_seg: 0.2970, decode.cascade_2.acc_seg: 71.9741, loss: 1.5769
2021-08-27 13:44:55,259 - mmseg - INFO - Iter [2850/80000]	lr: 9.682e-03, eta: 8:36:56, time: 0.217, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.6815, decode.final.acc_seg: 72.0592, decode.4x.loss_seg: 0.2726, decode.4x.acc_seg: 72.0592, decode.cascade_1.loss_seg: 0.2787, decode.cascade_1.acc_seg: 72.1430, decode.cascade_2.loss_seg: 0.2892, decode.cascade_2.acc_seg: 71.4324, loss: 1.5219
2021-08-27 13:45:14,766 - mmseg - INFO - Iter [2900/80000]	lr: 9.677e-03, eta: 8:36:18, time: 0.388, data_time: 0.020, memory: 18549, decode.final.loss_seg: 0.6673, decode.final.acc_seg: 72.7588, decode.4x.loss_seg: 0.2669, decode.4x.acc_seg: 72.7588, decode.cascade_1.loss_seg: 0.2746, decode.cascade_1.acc_seg: 72.5631, decode.cascade_2.loss_seg: 0.2845, decode.cascade_2.acc_seg: 71.9633, loss: 1.4934
2021-08-27 13:45:25,968 - mmseg - INFO - Iter [2950/80000]	lr: 9.671e-03, eta: 8:32:08, time: 0.226, data_time: 0.008, memory: 18549, decode.final.loss_seg: 0.5865, decode.final.acc_seg: 76.4698, decode.4x.loss_seg: 0.2346, decode.4x.acc_seg: 76.4698, decode.cascade_1.loss_seg: 0.2446, decode.cascade_1.acc_seg: 76.2557, decode.cascade_2.loss_seg: 0.2533, decode.cascade_2.acc_seg: 75.5936, loss: 1.3189
2021-08-27 13:45:39,118 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 13:45:39,138 - mmseg - INFO - Iter [3000/80000]	lr: 9.665e-03, eta: 8:28:54, time: 0.263, data_time: 0.045, memory: 18549, decode.final.loss_seg: 0.6624, decode.final.acc_seg: 73.4068, decode.4x.loss_seg: 0.2650, decode.4x.acc_seg: 73.4068, decode.cascade_1.loss_seg: 0.2704, decode.cascade_1.acc_seg: 73.2218, decode.cascade_2.loss_seg: 0.2806, decode.cascade_2.acc_seg: 72.6604, loss: 1.4784
2021-08-27 13:45:49,606 - mmseg - INFO - Iter [3050/80000]	lr: 9.660e-03, eta: 8:24:38, time: 0.209, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.6387, decode.final.acc_seg: 75.2713, decode.4x.loss_seg: 0.2555, decode.4x.acc_seg: 75.2713, decode.cascade_1.loss_seg: 0.2644, decode.cascade_1.acc_seg: 74.9500, decode.cascade_2.loss_seg: 0.2750, decode.cascade_2.acc_seg: 74.1496, loss: 1.4337
2021-08-27 13:46:02,344 - mmseg - INFO - Iter [3100/80000]	lr: 9.654e-03, eta: 8:21:26, time: 0.254, data_time: 0.022, memory: 18549, decode.final.loss_seg: 0.6230, decode.final.acc_seg: 75.2244, decode.4x.loss_seg: 0.2492, decode.4x.acc_seg: 75.2244, decode.cascade_1.loss_seg: 0.2616, decode.cascade_1.acc_seg: 74.4862, decode.cascade_2.loss_seg: 0.2720, decode.cascade_2.acc_seg: 73.7730, loss: 1.4058
2021-08-27 13:46:20,758 - mmseg - INFO - Iter [3150/80000]	lr: 9.649e-03, eta: 8:20:39, time: 0.369, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.6245, decode.final.acc_seg: 74.9363, decode.4x.loss_seg: 0.2498, decode.4x.acc_seg: 74.9363, decode.cascade_1.loss_seg: 0.2601, decode.cascade_1.acc_seg: 74.5989, decode.cascade_2.loss_seg: 0.2697, decode.cascade_2.acc_seg: 73.9153, loss: 1.4041
2021-08-27 13:46:38,726 - mmseg - INFO - Iter [3200/80000]	lr: 9.643e-03, eta: 8:19:40, time: 0.358, data_time: 0.050, memory: 18549, decode.final.loss_seg: 0.6517, decode.final.acc_seg: 73.6165, decode.4x.loss_seg: 0.2607, decode.4x.acc_seg: 73.6165, decode.cascade_1.loss_seg: 0.2679, decode.cascade_1.acc_seg: 73.2795, decode.cascade_2.loss_seg: 0.2768, decode.cascade_2.acc_seg: 72.6815, loss: 1.4571
2021-08-27 13:46:52,451 - mmseg - INFO - Iter [3250/80000]	lr: 9.637e-03, eta: 8:17:04, time: 0.274, data_time: 0.015, memory: 18549, decode.final.loss_seg: 0.6027, decode.final.acc_seg: 75.1109, decode.4x.loss_seg: 0.2411, decode.4x.acc_seg: 75.1109, decode.cascade_1.loss_seg: 0.2514, decode.cascade_1.acc_seg: 74.8094, decode.cascade_2.loss_seg: 0.2598, decode.cascade_2.acc_seg: 74.2714, loss: 1.3550
2021-08-27 13:47:20,978 - mmseg - INFO - Iter [3300/80000]	lr: 9.632e-03, eta: 8:20:14, time: 0.569, data_time: 0.073, memory: 18549, decode.final.loss_seg: 0.6541, decode.final.acc_seg: 73.7285, decode.4x.loss_seg: 0.2616, decode.4x.acc_seg: 73.7285, decode.cascade_1.loss_seg: 0.2716, decode.cascade_1.acc_seg: 73.4597, decode.cascade_2.loss_seg: 0.2806, decode.cascade_2.acc_seg: 72.9397, loss: 1.4680
2021-08-27 13:47:42,932 - mmseg - INFO - Iter [3350/80000]	lr: 9.626e-03, eta: 8:20:51, time: 0.441, data_time: 0.050, memory: 18549, decode.final.loss_seg: 0.5690, decode.final.acc_seg: 76.6536, decode.4x.loss_seg: 0.2276, decode.4x.acc_seg: 76.6536, decode.cascade_1.loss_seg: 0.2375, decode.cascade_1.acc_seg: 76.2781, decode.cascade_2.loss_seg: 0.2481, decode.cascade_2.acc_seg: 75.6454, loss: 1.2822
2021-08-27 13:47:54,596 - mmseg - INFO - Iter [3400/80000]	lr: 9.621e-03, eta: 8:17:33, time: 0.234, data_time: 0.036, memory: 18549, decode.final.loss_seg: 0.5908, decode.final.acc_seg: 76.8599, decode.4x.loss_seg: 0.2363, decode.4x.acc_seg: 76.8599, decode.cascade_1.loss_seg: 0.2460, decode.cascade_1.acc_seg: 76.5191, decode.cascade_2.loss_seg: 0.2568, decode.cascade_2.acc_seg: 75.8144, loss: 1.3300
2021-08-27 13:48:24,040 - mmseg - INFO - Iter [3450/80000]	lr: 9.615e-03, eta: 8:20:53, time: 0.587, data_time: 0.068, memory: 18549, decode.final.loss_seg: 0.6191, decode.final.acc_seg: 75.6870, decode.4x.loss_seg: 0.2476, decode.4x.acc_seg: 75.6870, decode.cascade_1.loss_seg: 0.2551, decode.cascade_1.acc_seg: 75.3846, decode.cascade_2.loss_seg: 0.2626, decode.cascade_2.acc_seg: 74.8017, loss: 1.3845
2021-08-27 13:48:41,441 - mmseg - INFO - Iter [3500/80000]	lr: 9.609e-03, eta: 8:19:45, time: 0.349, data_time: 0.036, memory: 18549, decode.final.loss_seg: 0.6079, decode.final.acc_seg: 74.5894, decode.4x.loss_seg: 0.2432, decode.4x.acc_seg: 74.5894, decode.cascade_1.loss_seg: 0.2512, decode.cascade_1.acc_seg: 74.1044, decode.cascade_2.loss_seg: 0.2608, decode.cascade_2.acc_seg: 73.5677, loss: 1.3630
2021-08-27 13:49:03,305 - mmseg - INFO - Iter [3550/80000]	lr: 9.604e-03, eta: 8:20:13, time: 0.436, data_time: 0.084, memory: 18549, decode.final.loss_seg: 0.5779, decode.final.acc_seg: 75.7749, decode.4x.loss_seg: 0.2312, decode.4x.acc_seg: 75.7749, decode.cascade_1.loss_seg: 0.2399, decode.cascade_1.acc_seg: 75.5203, decode.cascade_2.loss_seg: 0.2508, decode.cascade_2.acc_seg: 74.8462, loss: 1.2999
2021-08-27 13:49:42,439 - mmseg - INFO - Iter [3600/80000]	lr: 9.598e-03, eta: 8:26:45, time: 0.780, data_time: 0.049, memory: 18549, decode.final.loss_seg: 0.5921, decode.final.acc_seg: 76.2818, decode.4x.loss_seg: 0.2368, decode.4x.acc_seg: 76.2818, decode.cascade_1.loss_seg: 0.2463, decode.cascade_1.acc_seg: 75.9440, decode.cascade_2.loss_seg: 0.2565, decode.cascade_2.acc_seg: 75.4491, loss: 1.3318
2021-08-27 13:49:54,338 - mmseg - INFO - Iter [3650/80000]	lr: 9.593e-03, eta: 8:23:41, time: 0.242, data_time: 0.032, memory: 18549, decode.final.loss_seg: 0.6087, decode.final.acc_seg: 74.8438, decode.4x.loss_seg: 0.2435, decode.4x.acc_seg: 74.8438, decode.cascade_1.loss_seg: 0.2506, decode.cascade_1.acc_seg: 74.5716, decode.cascade_2.loss_seg: 0.2596, decode.cascade_2.acc_seg: 73.9123, loss: 1.3624
2021-08-27 13:50:12,271 - mmseg - INFO - Iter [3700/80000]	lr: 9.587e-03, eta: 8:22:45, time: 0.360, data_time: 0.017, memory: 18549, decode.final.loss_seg: 0.5858, decode.final.acc_seg: 77.0201, decode.4x.loss_seg: 0.2343, decode.4x.acc_seg: 77.0201, decode.cascade_1.loss_seg: 0.2453, decode.cascade_1.acc_seg: 76.4640, decode.cascade_2.loss_seg: 0.2553, decode.cascade_2.acc_seg: 75.7451, loss: 1.3207
2021-08-27 13:50:29,080 - mmseg - INFO - Iter [3750/80000]	lr: 9.581e-03, eta: 8:21:24, time: 0.336, data_time: 0.088, memory: 18549, decode.final.loss_seg: 0.5974, decode.final.acc_seg: 75.9660, decode.4x.loss_seg: 0.2390, decode.4x.acc_seg: 75.9660, decode.cascade_1.loss_seg: 0.2479, decode.cascade_1.acc_seg: 75.5669, decode.cascade_2.loss_seg: 0.2582, decode.cascade_2.acc_seg: 74.9609, loss: 1.3425
2021-08-27 13:50:51,926 - mmseg - INFO - Iter [3800/80000]	lr: 9.576e-03, eta: 8:22:06, time: 0.456, data_time: 0.023, memory: 18549, decode.final.loss_seg: 0.5385, decode.final.acc_seg: 77.2963, decode.4x.loss_seg: 0.2154, decode.4x.acc_seg: 77.2963, decode.cascade_1.loss_seg: 0.2247, decode.cascade_1.acc_seg: 76.9331, decode.cascade_2.loss_seg: 0.2350, decode.cascade_2.acc_seg: 76.2497, loss: 1.2135
2021-08-27 13:51:09,493 - mmseg - INFO - Iter [3850/80000]	lr: 9.570e-03, eta: 8:21:04, time: 0.353, data_time: 0.084, memory: 18549, decode.final.loss_seg: 0.5754, decode.final.acc_seg: 76.8866, decode.4x.loss_seg: 0.2302, decode.4x.acc_seg: 76.8866, decode.cascade_1.loss_seg: 0.2382, decode.cascade_1.acc_seg: 76.5485, decode.cascade_2.loss_seg: 0.2480, decode.cascade_2.acc_seg: 75.9667, loss: 1.2918
2021-08-27 13:51:29,265 - mmseg - INFO - Iter [3900/80000]	lr: 9.565e-03, eta: 8:20:44, time: 0.394, data_time: 0.020, memory: 18549, decode.final.loss_seg: 0.6329, decode.final.acc_seg: 74.5456, decode.4x.loss_seg: 0.2532, decode.4x.acc_seg: 74.5456, decode.cascade_1.loss_seg: 0.2626, decode.cascade_1.acc_seg: 74.2369, decode.cascade_2.loss_seg: 0.2718, decode.cascade_2.acc_seg: 73.6208, loss: 1.4205
2021-08-27 13:51:50,531 - mmseg - INFO - Iter [3950/80000]	lr: 9.559e-03, eta: 8:20:53, time: 0.424, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.5950, decode.final.acc_seg: 74.3445, decode.4x.loss_seg: 0.2380, decode.4x.acc_seg: 74.3445, decode.cascade_1.loss_seg: 0.2464, decode.cascade_1.acc_seg: 74.0799, decode.cascade_2.loss_seg: 0.2557, decode.cascade_2.acc_seg: 73.4167, loss: 1.3350
2021-08-27 13:52:03,317 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 13:52:03,338 - mmseg - INFO - Iter [4000/80000]	lr: 9.553e-03, eta: 8:18:23, time: 0.259, data_time: 0.029, memory: 18549, decode.final.loss_seg: 0.5550, decode.final.acc_seg: 77.8460, decode.4x.loss_seg: 0.2220, decode.4x.acc_seg: 77.8460, decode.cascade_1.loss_seg: 0.2319, decode.cascade_1.acc_seg: 77.4055, decode.cascade_2.loss_seg: 0.2420, decode.cascade_2.acc_seg: 76.7922, loss: 1.2508
2021-08-27 13:52:20,550 - mmseg - INFO - Iter [4050/80000]	lr: 9.548e-03, eta: 8:17:16, time: 0.343, data_time: 0.035, memory: 18549, decode.final.loss_seg: 0.5567, decode.final.acc_seg: 76.4741, decode.4x.loss_seg: 0.2227, decode.4x.acc_seg: 76.4741, decode.cascade_1.loss_seg: 0.2305, decode.cascade_1.acc_seg: 76.2265, decode.cascade_2.loss_seg: 0.2392, decode.cascade_2.acc_seg: 75.7185, loss: 1.2491
2021-08-27 13:52:32,223 - mmseg - INFO - Iter [4100/80000]	lr: 9.542e-03, eta: 8:14:30, time: 0.235, data_time: 0.022, memory: 18549, decode.final.loss_seg: 0.5879, decode.final.acc_seg: 76.4667, decode.4x.loss_seg: 0.2352, decode.4x.acc_seg: 76.4667, decode.cascade_1.loss_seg: 0.2459, decode.cascade_1.acc_seg: 75.9672, decode.cascade_2.loss_seg: 0.2562, decode.cascade_2.acc_seg: 75.3285, loss: 1.3252
2021-08-27 13:52:45,678 - mmseg - INFO - Iter [4150/80000]	lr: 9.537e-03, eta: 8:12:18, time: 0.267, data_time: 0.022, memory: 18549, decode.final.loss_seg: 0.5491, decode.final.acc_seg: 77.6190, decode.4x.loss_seg: 0.2197, decode.4x.acc_seg: 77.6190, decode.cascade_1.loss_seg: 0.2284, decode.cascade_1.acc_seg: 77.3279, decode.cascade_2.loss_seg: 0.2380, decode.cascade_2.acc_seg: 76.7126, loss: 1.2352
2021-08-27 13:53:00,401 - mmseg - INFO - Iter [4200/80000]	lr: 9.531e-03, eta: 8:10:33, time: 0.295, data_time: 0.029, memory: 18549, decode.final.loss_seg: 0.5557, decode.final.acc_seg: 76.7004, decode.4x.loss_seg: 0.2223, decode.4x.acc_seg: 76.7004, decode.cascade_1.loss_seg: 0.2319, decode.cascade_1.acc_seg: 76.1690, decode.cascade_2.loss_seg: 0.2419, decode.cascade_2.acc_seg: 75.5286, loss: 1.2519
2021-08-27 13:53:17,263 - mmseg - INFO - Iter [4250/80000]	lr: 9.525e-03, eta: 8:09:24, time: 0.333, data_time: 0.033, memory: 18549, decode.final.loss_seg: 0.5984, decode.final.acc_seg: 76.3015, decode.4x.loss_seg: 0.2394, decode.4x.acc_seg: 76.3015, decode.cascade_1.loss_seg: 0.2468, decode.cascade_1.acc_seg: 75.9793, decode.cascade_2.loss_seg: 0.2569, decode.cascade_2.acc_seg: 75.3177, loss: 1.3415
2021-08-27 13:53:29,772 - mmseg - INFO - Iter [4300/80000]	lr: 9.520e-03, eta: 8:07:09, time: 0.255, data_time: 0.035, memory: 18549, decode.final.loss_seg: 0.5515, decode.final.acc_seg: 76.6316, decode.4x.loss_seg: 0.2206, decode.4x.acc_seg: 76.6316, decode.cascade_1.loss_seg: 0.2301, decode.cascade_1.acc_seg: 76.1382, decode.cascade_2.loss_seg: 0.2403, decode.cascade_2.acc_seg: 75.4584, loss: 1.2425
2021-08-27 13:53:54,152 - mmseg - INFO - Iter [4350/80000]	lr: 9.514e-03, eta: 8:08:16, time: 0.486, data_time: 0.127, memory: 18549, decode.final.loss_seg: 0.5620, decode.final.acc_seg: 76.0472, decode.4x.loss_seg: 0.2248, decode.4x.acc_seg: 76.0472, decode.cascade_1.loss_seg: 0.2321, decode.cascade_1.acc_seg: 75.7069, decode.cascade_2.loss_seg: 0.2418, decode.cascade_2.acc_seg: 75.0695, loss: 1.2606
2021-08-27 13:54:06,188 - mmseg - INFO - Iter [4400/80000]	lr: 9.509e-03, eta: 8:05:51, time: 0.241, data_time: 0.011, memory: 18549, decode.final.loss_seg: 0.5559, decode.final.acc_seg: 76.4882, decode.4x.loss_seg: 0.2223, decode.4x.acc_seg: 76.4882, decode.cascade_1.loss_seg: 0.2326, decode.cascade_1.acc_seg: 76.0294, decode.cascade_2.loss_seg: 0.2426, decode.cascade_2.acc_seg: 75.4569, loss: 1.2534
2021-08-27 13:54:29,107 - mmseg - INFO - Iter [4450/80000]	lr: 9.503e-03, eta: 8:06:34, time: 0.458, data_time: 0.097, memory: 18549, decode.final.loss_seg: 0.5832, decode.final.acc_seg: 75.7729, decode.4x.loss_seg: 0.2333, decode.4x.acc_seg: 75.7729, decode.cascade_1.loss_seg: 0.2399, decode.cascade_1.acc_seg: 75.5888, decode.cascade_2.loss_seg: 0.2502, decode.cascade_2.acc_seg: 74.9755, loss: 1.3066
2021-08-27 13:54:45,507 - mmseg - INFO - Iter [4500/80000]	lr: 9.497e-03, eta: 8:05:25, time: 0.328, data_time: 0.052, memory: 18549, decode.final.loss_seg: 0.5677, decode.final.acc_seg: 75.1872, decode.4x.loss_seg: 0.2271, decode.4x.acc_seg: 75.1872, decode.cascade_1.loss_seg: 0.2354, decode.cascade_1.acc_seg: 74.7225, decode.cascade_2.loss_seg: 0.2445, decode.cascade_2.acc_seg: 74.1493, loss: 1.2747
2021-08-27 13:55:02,839 - mmseg - INFO - Iter [4550/80000]	lr: 9.492e-03, eta: 8:04:34, time: 0.348, data_time: 0.015, memory: 18549, decode.final.loss_seg: 0.5080, decode.final.acc_seg: 78.4485, decode.4x.loss_seg: 0.2032, decode.4x.acc_seg: 78.4485, decode.cascade_1.loss_seg: 0.2130, decode.cascade_1.acc_seg: 77.9583, decode.cascade_2.loss_seg: 0.2229, decode.cascade_2.acc_seg: 77.3365, loss: 1.1471
2021-08-27 13:55:19,935 - mmseg - INFO - Iter [4600/80000]	lr: 9.486e-03, eta: 8:03:38, time: 0.340, data_time: 0.012, memory: 18549, decode.final.loss_seg: 0.5933, decode.final.acc_seg: 75.7584, decode.4x.loss_seg: 0.2373, decode.4x.acc_seg: 75.7584, decode.cascade_1.loss_seg: 0.2452, decode.cascade_1.acc_seg: 75.3152, decode.cascade_2.loss_seg: 0.2557, decode.cascade_2.acc_seg: 74.5916, loss: 1.3316
2021-08-27 13:55:30,863 - mmseg - INFO - Iter [4650/80000]	lr: 9.481e-03, eta: 8:01:04, time: 0.219, data_time: 0.030, memory: 18549, decode.final.loss_seg: 0.5584, decode.final.acc_seg: 76.7598, decode.4x.loss_seg: 0.2234, decode.4x.acc_seg: 76.7598, decode.cascade_1.loss_seg: 0.2325, decode.cascade_1.acc_seg: 76.2706, decode.cascade_2.loss_seg: 0.2437, decode.cascade_2.acc_seg: 75.6430, loss: 1.2580
2021-08-27 13:55:44,590 - mmseg - INFO - Iter [4700/80000]	lr: 9.475e-03, eta: 7:59:19, time: 0.276, data_time: 0.053, memory: 18549, decode.final.loss_seg: 0.5483, decode.final.acc_seg: 77.6802, decode.4x.loss_seg: 0.2193, decode.4x.acc_seg: 77.6802, decode.cascade_1.loss_seg: 0.2273, decode.cascade_1.acc_seg: 77.3499, decode.cascade_2.loss_seg: 0.2379, decode.cascade_2.acc_seg: 76.5942, loss: 1.2327
2021-08-27 13:56:11,131 - mmseg - INFO - Iter [4750/80000]	lr: 9.469e-03, eta: 8:00:57, time: 0.530, data_time: 0.090, memory: 18549, decode.final.loss_seg: 0.5256, decode.final.acc_seg: 76.0421, decode.4x.loss_seg: 0.2102, decode.4x.acc_seg: 76.0421, decode.cascade_1.loss_seg: 0.2193, decode.cascade_1.acc_seg: 75.6650, decode.cascade_2.loss_seg: 0.2302, decode.cascade_2.acc_seg: 74.9401, loss: 1.1853
2021-08-27 13:56:29,352 - mmseg - INFO - Iter [4800/80000]	lr: 9.464e-03, eta: 8:00:24, time: 0.366, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.5751, decode.final.acc_seg: 76.7326, decode.4x.loss_seg: 0.2300, decode.4x.acc_seg: 76.7326, decode.cascade_1.loss_seg: 0.2391, decode.cascade_1.acc_seg: 76.3439, decode.cascade_2.loss_seg: 0.2491, decode.cascade_2.acc_seg: 75.7359, loss: 1.2934
2021-08-27 13:56:52,552 - mmseg - INFO - Iter [4850/80000]	lr: 9.458e-03, eta: 8:01:05, time: 0.461, data_time: 0.030, memory: 18549, decode.final.loss_seg: 0.5394, decode.final.acc_seg: 77.4009, decode.4x.loss_seg: 0.2158, decode.4x.acc_seg: 77.4009, decode.cascade_1.loss_seg: 0.2242, decode.cascade_1.acc_seg: 76.9753, decode.cascade_2.loss_seg: 0.2350, decode.cascade_2.acc_seg: 76.2912, loss: 1.2143
2021-08-27 13:57:10,751 - mmseg - INFO - Iter [4900/80000]	lr: 9.453e-03, eta: 8:00:32, time: 0.366, data_time: 0.048, memory: 18549, decode.final.loss_seg: 0.5632, decode.final.acc_seg: 76.9714, decode.4x.loss_seg: 0.2253, decode.4x.acc_seg: 76.9714, decode.cascade_1.loss_seg: 0.2318, decode.cascade_1.acc_seg: 76.7887, decode.cascade_2.loss_seg: 0.2413, decode.cascade_2.acc_seg: 76.2186, loss: 1.2616
2021-08-27 13:57:24,633 - mmseg - INFO - Iter [4950/80000]	lr: 9.447e-03, eta: 7:58:53, time: 0.278, data_time: 0.011, memory: 18549, decode.final.loss_seg: 0.5646, decode.final.acc_seg: 76.6773, decode.4x.loss_seg: 0.2258, decode.4x.acc_seg: 76.6773, decode.cascade_1.loss_seg: 0.2320, decode.cascade_1.acc_seg: 76.4150, decode.cascade_2.loss_seg: 0.2417, decode.cascade_2.acc_seg: 75.7531, loss: 1.2641
2021-08-27 13:57:45,550 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 13:57:45,591 - mmseg - INFO - Iter [5000/80000]	lr: 9.441e-03, eta: 7:59:00, time: 0.417, data_time: 0.065, memory: 18549, decode.final.loss_seg: 0.5289, decode.final.acc_seg: 78.4676, decode.4x.loss_seg: 0.2116, decode.4x.acc_seg: 78.4676, decode.cascade_1.loss_seg: 0.2198, decode.cascade_1.acc_seg: 78.0405, decode.cascade_2.loss_seg: 0.2306, decode.cascade_2.acc_seg: 77.3924, loss: 1.1909
2021-08-27 13:58:16,756 - mmseg - INFO - Iter [5050/80000]	lr: 9.436e-03, eta: 8:01:39, time: 0.624, data_time: 0.108, memory: 18549, decode.final.loss_seg: 0.5737, decode.final.acc_seg: 77.1134, decode.4x.loss_seg: 0.2295, decode.4x.acc_seg: 77.1134, decode.cascade_1.loss_seg: 0.2396, decode.cascade_1.acc_seg: 76.6121, decode.cascade_2.loss_seg: 0.2508, decode.cascade_2.acc_seg: 75.9387, loss: 1.2936
2021-08-27 13:58:44,914 - mmseg - INFO - Iter [5100/80000]	lr: 9.430e-03, eta: 8:03:27, time: 0.558, data_time: 0.020, memory: 18549, decode.final.loss_seg: 0.5643, decode.final.acc_seg: 75.4446, decode.4x.loss_seg: 0.2257, decode.4x.acc_seg: 75.4446, decode.cascade_1.loss_seg: 0.2346, decode.cascade_1.acc_seg: 74.8958, decode.cascade_2.loss_seg: 0.2446, decode.cascade_2.acc_seg: 74.3093, loss: 1.2692
2021-08-27 13:59:09,071 - mmseg - INFO - Iter [5150/80000]	lr: 9.425e-03, eta: 8:04:17, time: 0.483, data_time: 0.030, memory: 18549, decode.final.loss_seg: 0.5479, decode.final.acc_seg: 77.9123, decode.4x.loss_seg: 0.2192, decode.4x.acc_seg: 77.9123, decode.cascade_1.loss_seg: 0.2285, decode.cascade_1.acc_seg: 77.3697, decode.cascade_2.loss_seg: 0.2380, decode.cascade_2.acc_seg: 76.7264, loss: 1.2336
2021-08-27 13:59:40,559 - mmseg - INFO - Iter [5200/80000]	lr: 9.419e-03, eta: 8:06:53, time: 0.632, data_time: 0.054, memory: 18549, decode.final.loss_seg: 0.5596, decode.final.acc_seg: 76.6570, decode.4x.loss_seg: 0.2238, decode.4x.acc_seg: 76.6570, decode.cascade_1.loss_seg: 0.2326, decode.cascade_1.acc_seg: 76.1733, decode.cascade_2.loss_seg: 0.2433, decode.cascade_2.acc_seg: 75.5126, loss: 1.2594
2021-08-27 13:59:59,418 - mmseg - INFO - Iter [5250/80000]	lr: 9.413e-03, eta: 8:06:26, time: 0.379, data_time: 0.033, memory: 18549, decode.final.loss_seg: 0.5714, decode.final.acc_seg: 76.0756, decode.4x.loss_seg: 0.2286, decode.4x.acc_seg: 76.0756, decode.cascade_1.loss_seg: 0.2374, decode.cascade_1.acc_seg: 75.7314, decode.cascade_2.loss_seg: 0.2486, decode.cascade_2.acc_seg: 75.0032, loss: 1.2860
2021-08-27 14:00:32,353 - mmseg - INFO - Iter [5300/80000]	lr: 9.408e-03, eta: 8:09:14, time: 0.657, data_time: 0.125, memory: 18549, decode.final.loss_seg: 0.5512, decode.final.acc_seg: 76.1927, decode.4x.loss_seg: 0.2205, decode.4x.acc_seg: 76.1927, decode.cascade_1.loss_seg: 0.2267, decode.cascade_1.acc_seg: 75.8844, decode.cascade_2.loss_seg: 0.2357, decode.cascade_2.acc_seg: 75.2967, loss: 1.2341
2021-08-27 14:00:57,080 - mmseg - INFO - Iter [5350/80000]	lr: 9.402e-03, eta: 8:10:06, time: 0.497, data_time: 0.070, memory: 18549, decode.final.loss_seg: 0.5463, decode.final.acc_seg: 77.3743, decode.4x.loss_seg: 0.2185, decode.4x.acc_seg: 77.3743, decode.cascade_1.loss_seg: 0.2266, decode.cascade_1.acc_seg: 76.9166, decode.cascade_2.loss_seg: 0.2370, decode.cascade_2.acc_seg: 76.2710, loss: 1.2284
2021-08-27 14:01:08,563 - mmseg - INFO - Iter [5400/80000]	lr: 9.397e-03, eta: 8:07:54, time: 0.231, data_time: 0.008, memory: 18549, decode.final.loss_seg: 0.5048, decode.final.acc_seg: 78.9541, decode.4x.loss_seg: 0.2019, decode.4x.acc_seg: 78.9541, decode.cascade_1.loss_seg: 0.2124, decode.cascade_1.acc_seg: 78.3681, decode.cascade_2.loss_seg: 0.2228, decode.cascade_2.acc_seg: 77.7464, loss: 1.1419
2021-08-27 14:01:30,556 - mmseg - INFO - Iter [5450/80000]	lr: 9.391e-03, eta: 8:08:06, time: 0.439, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.5629, decode.final.acc_seg: 77.7636, decode.4x.loss_seg: 0.2252, decode.4x.acc_seg: 77.7636, decode.cascade_1.loss_seg: 0.2317, decode.cascade_1.acc_seg: 77.3798, decode.cascade_2.loss_seg: 0.2412, decode.cascade_2.acc_seg: 76.7611, loss: 1.2610
2021-08-27 14:01:56,410 - mmseg - INFO - Iter [5500/80000]	lr: 9.385e-03, eta: 8:09:08, time: 0.513, data_time: 0.066, memory: 18549, decode.final.loss_seg: 0.5620, decode.final.acc_seg: 77.1965, decode.4x.loss_seg: 0.2248, decode.4x.acc_seg: 77.1965, decode.cascade_1.loss_seg: 0.2311, decode.cascade_1.acc_seg: 76.8750, decode.cascade_2.loss_seg: 0.2400, decode.cascade_2.acc_seg: 76.3293, loss: 1.2580
2021-08-27 14:02:15,180 - mmseg - INFO - Iter [5550/80000]	lr: 9.380e-03, eta: 8:08:39, time: 0.380, data_time: 0.123, memory: 18549, decode.final.loss_seg: 0.5365, decode.final.acc_seg: 76.5702, decode.4x.loss_seg: 0.2146, decode.4x.acc_seg: 76.5702, decode.cascade_1.loss_seg: 0.2230, decode.cascade_1.acc_seg: 76.1091, decode.cascade_2.loss_seg: 0.2330, decode.cascade_2.acc_seg: 75.4564, loss: 1.2070
2021-08-27 14:02:58,260 - mmseg - INFO - Iter [5600/80000]	lr: 9.374e-03, eta: 8:13:29, time: 0.859, data_time: 0.209, memory: 18549, decode.final.loss_seg: 0.5203, decode.final.acc_seg: 78.4269, decode.4x.loss_seg: 0.2081, decode.4x.acc_seg: 78.4269, decode.cascade_1.loss_seg: 0.2173, decode.cascade_1.acc_seg: 78.0225, decode.cascade_2.loss_seg: 0.2288, decode.cascade_2.acc_seg: 77.3482, loss: 1.1746
2021-08-27 14:03:29,068 - mmseg - INFO - Iter [5650/80000]	lr: 9.369e-03, eta: 8:15:33, time: 0.617, data_time: 0.068, memory: 18549, decode.final.loss_seg: 0.4964, decode.final.acc_seg: 78.4409, decode.4x.loss_seg: 0.1986, decode.4x.acc_seg: 78.4409, decode.cascade_1.loss_seg: 0.2066, decode.cascade_1.acc_seg: 78.0388, decode.cascade_2.loss_seg: 0.2167, decode.cascade_2.acc_seg: 77.4357, loss: 1.1183
2021-08-27 14:03:49,667 - mmseg - INFO - Iter [5700/80000]	lr: 9.363e-03, eta: 8:15:20, time: 0.410, data_time: 0.012, memory: 18549, decode.final.loss_seg: 0.5415, decode.final.acc_seg: 77.6877, decode.4x.loss_seg: 0.2166, decode.4x.acc_seg: 77.6877, decode.cascade_1.loss_seg: 0.2228, decode.cascade_1.acc_seg: 77.4344, decode.cascade_2.loss_seg: 0.2327, decode.cascade_2.acc_seg: 76.8197, loss: 1.2136
2021-08-27 14:04:20,631 - mmseg - INFO - Iter [5750/80000]	lr: 9.357e-03, eta: 8:17:22, time: 0.621, data_time: 0.025, memory: 18549, decode.final.loss_seg: 0.5631, decode.final.acc_seg: 77.8096, decode.4x.loss_seg: 0.2252, decode.4x.acc_seg: 77.8096, decode.cascade_1.loss_seg: 0.2312, decode.cascade_1.acc_seg: 77.4366, decode.cascade_2.loss_seg: 0.2407, decode.cascade_2.acc_seg: 76.8189, loss: 1.2603
2021-08-27 14:04:34,987 - mmseg - INFO - Iter [5800/80000]	lr: 9.352e-03, eta: 8:15:50, time: 0.288, data_time: 0.025, memory: 18549, decode.final.loss_seg: 0.5029, decode.final.acc_seg: 78.2887, decode.4x.loss_seg: 0.2012, decode.4x.acc_seg: 78.2887, decode.cascade_1.loss_seg: 0.2090, decode.cascade_1.acc_seg: 77.8973, decode.cascade_2.loss_seg: 0.2199, decode.cascade_2.acc_seg: 77.1441, loss: 1.1330
2021-08-27 14:04:55,032 - mmseg - INFO - Iter [5850/80000]	lr: 9.346e-03, eta: 8:15:29, time: 0.400, data_time: 0.010, memory: 18549, decode.final.loss_seg: 0.5578, decode.final.acc_seg: 76.6286, decode.4x.loss_seg: 0.2231, decode.4x.acc_seg: 76.6286, decode.cascade_1.loss_seg: 0.2295, decode.cascade_1.acc_seg: 76.2528, decode.cascade_2.loss_seg: 0.2397, decode.cascade_2.acc_seg: 75.6254, loss: 1.2502
2021-08-27 14:05:09,819 - mmseg - INFO - Iter [5900/80000]	lr: 9.341e-03, eta: 8:14:01, time: 0.294, data_time: 0.015, memory: 18549, decode.final.loss_seg: 0.5380, decode.final.acc_seg: 77.0410, decode.4x.loss_seg: 0.2152, decode.4x.acc_seg: 77.0410, decode.cascade_1.loss_seg: 0.2219, decode.cascade_1.acc_seg: 76.7393, decode.cascade_2.loss_seg: 0.2318, decode.cascade_2.acc_seg: 76.2775, loss: 1.2070
2021-08-27 14:05:29,114 - mmseg - INFO - Iter [5950/80000]	lr: 9.335e-03, eta: 8:13:34, time: 0.389, data_time: 0.016, memory: 18549, decode.final.loss_seg: 0.5324, decode.final.acc_seg: 77.2933, decode.4x.loss_seg: 0.2129, decode.4x.acc_seg: 77.2933, decode.cascade_1.loss_seg: 0.2201, decode.cascade_1.acc_seg: 76.7799, decode.cascade_2.loss_seg: 0.2305, decode.cascade_2.acc_seg: 76.0368, loss: 1.1960
2021-08-27 14:05:45,186 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 14:05:45,231 - mmseg - INFO - Iter [6000/80000]	lr: 9.329e-03, eta: 8:12:26, time: 0.322, data_time: 0.065, memory: 18549, decode.final.loss_seg: 0.5174, decode.final.acc_seg: 77.8998, decode.4x.loss_seg: 0.2070, decode.4x.acc_seg: 77.8998, decode.cascade_1.loss_seg: 0.2156, decode.cascade_1.acc_seg: 77.4928, decode.cascade_2.loss_seg: 0.2258, decode.cascade_2.acc_seg: 76.9197, loss: 1.1658
2021-08-27 14:05:59,500 - mmseg - INFO - Iter [6050/80000]	lr: 9.324e-03, eta: 8:10:57, time: 0.286, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.5223, decode.final.acc_seg: 77.4462, decode.4x.loss_seg: 0.2089, decode.4x.acc_seg: 77.4462, decode.cascade_1.loss_seg: 0.2161, decode.cascade_1.acc_seg: 77.0129, decode.cascade_2.loss_seg: 0.2262, decode.cascade_2.acc_seg: 76.3892, loss: 1.1736
2021-08-27 14:06:28,506 - mmseg - INFO - Iter [6100/80000]	lr: 9.318e-03, eta: 8:12:26, time: 0.578, data_time: 0.037, memory: 18549, decode.final.loss_seg: 0.5183, decode.final.acc_seg: 78.0775, decode.4x.loss_seg: 0.2073, decode.4x.acc_seg: 78.0775, decode.cascade_1.loss_seg: 0.2154, decode.cascade_1.acc_seg: 77.6383, decode.cascade_2.loss_seg: 0.2257, decode.cascade_2.acc_seg: 77.0037, loss: 1.1667
2021-08-27 14:06:44,602 - mmseg - INFO - Iter [6150/80000]	lr: 9.312e-03, eta: 8:11:20, time: 0.324, data_time: 0.020, memory: 18549, decode.final.loss_seg: 0.5309, decode.final.acc_seg: 77.5004, decode.4x.loss_seg: 0.2124, decode.4x.acc_seg: 77.5004, decode.cascade_1.loss_seg: 0.2197, decode.cascade_1.acc_seg: 77.1747, decode.cascade_2.loss_seg: 0.2290, decode.cascade_2.acc_seg: 76.6056, loss: 1.1919
2021-08-27 14:06:57,130 - mmseg - INFO - Iter [6200/80000]	lr: 9.307e-03, eta: 8:09:32, time: 0.251, data_time: 0.047, memory: 18549, decode.final.loss_seg: 0.5037, decode.final.acc_seg: 77.6536, decode.4x.loss_seg: 0.2015, decode.4x.acc_seg: 77.6536, decode.cascade_1.loss_seg: 0.2090, decode.cascade_1.acc_seg: 77.3750, decode.cascade_2.loss_seg: 0.2187, decode.cascade_2.acc_seg: 76.7776, loss: 1.1329
2021-08-27 14:07:07,661 - mmseg - INFO - Iter [6250/80000]	lr: 9.301e-03, eta: 8:07:22, time: 0.210, data_time: 0.009, memory: 18549, decode.final.loss_seg: 0.4948, decode.final.acc_seg: 77.9161, decode.4x.loss_seg: 0.1979, decode.4x.acc_seg: 77.9161, decode.cascade_1.loss_seg: 0.2067, decode.cascade_1.acc_seg: 77.4414, decode.cascade_2.loss_seg: 0.2169, decode.cascade_2.acc_seg: 76.8142, loss: 1.1163
2021-08-27 14:07:21,652 - mmseg - INFO - Iter [6300/80000]	lr: 9.296e-03, eta: 8:05:53, time: 0.279, data_time: 0.013, memory: 18549, decode.final.loss_seg: 0.4973, decode.final.acc_seg: 78.2098, decode.4x.loss_seg: 0.1989, decode.4x.acc_seg: 78.2098, decode.cascade_1.loss_seg: 0.2067, decode.cascade_1.acc_seg: 77.7632, decode.cascade_2.loss_seg: 0.2172, decode.cascade_2.acc_seg: 77.0259, loss: 1.1201
2021-08-27 14:07:48,065 - mmseg - INFO - Iter [6350/80000]	lr: 9.290e-03, eta: 8:06:50, time: 0.528, data_time: 0.178, memory: 18549, decode.final.loss_seg: 0.5106, decode.final.acc_seg: 78.2283, decode.4x.loss_seg: 0.2042, decode.4x.acc_seg: 78.2283, decode.cascade_1.loss_seg: 0.2121, decode.cascade_1.acc_seg: 77.9051, decode.cascade_2.loss_seg: 0.2223, decode.cascade_2.acc_seg: 77.2583, loss: 1.1492
2021-08-27 14:08:02,959 - mmseg - INFO - Iter [6400/80000]	lr: 9.284e-03, eta: 8:05:34, time: 0.299, data_time: 0.012, memory: 18549, decode.final.loss_seg: 0.5093, decode.final.acc_seg: 77.7590, decode.4x.loss_seg: 0.2037, decode.4x.acc_seg: 77.7590, decode.cascade_1.loss_seg: 0.2138, decode.cascade_1.acc_seg: 77.1469, decode.cascade_2.loss_seg: 0.2242, decode.cascade_2.acc_seg: 76.5348, loss: 1.1510
2021-08-27 14:08:28,063 - mmseg - INFO - Iter [6450/80000]	lr: 9.279e-03, eta: 8:06:15, time: 0.502, data_time: 0.072, memory: 18549, decode.final.loss_seg: 0.5372, decode.final.acc_seg: 78.7532, decode.4x.loss_seg: 0.2149, decode.4x.acc_seg: 78.7532, decode.cascade_1.loss_seg: 0.2230, decode.cascade_1.acc_seg: 78.4435, decode.cascade_2.loss_seg: 0.2338, decode.cascade_2.acc_seg: 77.7377, loss: 1.2088
2021-08-27 14:08:47,567 - mmseg - INFO - Iter [6500/80000]	lr: 9.273e-03, eta: 8:05:46, time: 0.381, data_time: 0.038, memory: 18549, decode.final.loss_seg: 0.5131, decode.final.acc_seg: 78.4718, decode.4x.loss_seg: 0.2052, decode.4x.acc_seg: 78.4718, decode.cascade_1.loss_seg: 0.2130, decode.cascade_1.acc_seg: 78.1372, decode.cascade_2.loss_seg: 0.2236, decode.cascade_2.acc_seg: 77.4419, loss: 1.1549
2021-08-27 14:08:59,432 - mmseg - INFO - Iter [6550/80000]	lr: 9.268e-03, eta: 8:04:02, time: 0.246, data_time: 0.025, memory: 18549, decode.final.loss_seg: 0.5115, decode.final.acc_seg: 77.7093, decode.4x.loss_seg: 0.2046, decode.4x.acc_seg: 77.7093, decode.cascade_1.loss_seg: 0.2130, decode.cascade_1.acc_seg: 77.1549, decode.cascade_2.loss_seg: 0.2242, decode.cascade_2.acc_seg: 76.5145, loss: 1.1533
2021-08-27 14:09:10,379 - mmseg - INFO - Iter [6600/80000]	lr: 9.262e-03, eta: 8:02:04, time: 0.220, data_time: 0.030, memory: 18549, decode.final.loss_seg: 0.5013, decode.final.acc_seg: 78.1347, decode.4x.loss_seg: 0.2005, decode.4x.acc_seg: 78.1347, decode.cascade_1.loss_seg: 0.2082, decode.cascade_1.acc_seg: 77.6814, decode.cascade_2.loss_seg: 0.2184, decode.cascade_2.acc_seg: 77.0351, loss: 1.1285
2021-08-27 14:09:52,498 - mmseg - INFO - Iter [6650/80000]	lr: 9.256e-03, eta: 8:05:49, time: 0.838, data_time: 0.034, memory: 18549, decode.final.loss_seg: 0.5360, decode.final.acc_seg: 76.4469, decode.4x.loss_seg: 0.2144, decode.4x.acc_seg: 76.4469, decode.cascade_1.loss_seg: 0.2212, decode.cascade_1.acc_seg: 76.1710, decode.cascade_2.loss_seg: 0.2303, decode.cascade_2.acc_seg: 75.6333, loss: 1.2019
2021-08-27 14:10:27,386 - mmseg - INFO - Iter [6700/80000]	lr: 9.251e-03, eta: 8:08:15, time: 0.702, data_time: 0.101, memory: 18549, decode.final.loss_seg: 0.4937, decode.final.acc_seg: 79.5624, decode.4x.loss_seg: 0.1975, decode.4x.acc_seg: 79.5624, decode.cascade_1.loss_seg: 0.2051, decode.cascade_1.acc_seg: 79.2129, decode.cascade_2.loss_seg: 0.2160, decode.cascade_2.acc_seg: 78.5054, loss: 1.1123
2021-08-27 14:10:47,144 - mmseg - INFO - Iter [6750/80000]	lr: 9.245e-03, eta: 8:07:53, time: 0.395, data_time: 0.115, memory: 18549, decode.final.loss_seg: 0.5159, decode.final.acc_seg: 77.5471, decode.4x.loss_seg: 0.2064, decode.4x.acc_seg: 77.5471, decode.cascade_1.loss_seg: 0.2130, decode.cascade_1.acc_seg: 77.1119, decode.cascade_2.loss_seg: 0.2226, decode.cascade_2.acc_seg: 76.4910, loss: 1.1578
2021-08-27 14:11:14,857 - mmseg - INFO - Iter [6800/80000]	lr: 9.239e-03, eta: 8:08:56, time: 0.554, data_time: 0.107, memory: 18549, decode.final.loss_seg: 0.5123, decode.final.acc_seg: 78.9821, decode.4x.loss_seg: 0.2049, decode.4x.acc_seg: 78.9821, decode.cascade_1.loss_seg: 0.2113, decode.cascade_1.acc_seg: 78.7299, decode.cascade_2.loss_seg: 0.2219, decode.cascade_2.acc_seg: 78.0462, loss: 1.1505
2021-08-27 14:11:42,321 - mmseg - INFO - Iter [6850/80000]	lr: 9.234e-03, eta: 8:09:54, time: 0.547, data_time: 0.135, memory: 18549, decode.final.loss_seg: 0.5146, decode.final.acc_seg: 78.6491, decode.4x.loss_seg: 0.2058, decode.4x.acc_seg: 78.6491, decode.cascade_1.loss_seg: 0.2139, decode.cascade_1.acc_seg: 78.1842, decode.cascade_2.loss_seg: 0.2233, decode.cascade_2.acc_seg: 77.5559, loss: 1.1576
2021-08-27 14:12:16,330 - mmseg - INFO - Iter [6900/80000]	lr: 9.228e-03, eta: 8:12:03, time: 0.682, data_time: 0.142, memory: 18549, decode.final.loss_seg: 0.5071, decode.final.acc_seg: 78.1032, decode.4x.loss_seg: 0.2028, decode.4x.acc_seg: 78.1032, decode.cascade_1.loss_seg: 0.2108, decode.cascade_1.acc_seg: 77.5904, decode.cascade_2.loss_seg: 0.2210, decode.cascade_2.acc_seg: 77.0027, loss: 1.1417
2021-08-27 14:12:39,008 - mmseg - INFO - Iter [6950/80000]	lr: 9.223e-03, eta: 8:12:08, time: 0.452, data_time: 0.076, memory: 18549, decode.final.loss_seg: 0.5074, decode.final.acc_seg: 79.1414, decode.4x.loss_seg: 0.2030, decode.4x.acc_seg: 79.1414, decode.cascade_1.loss_seg: 0.2118, decode.cascade_1.acc_seg: 78.6135, decode.cascade_2.loss_seg: 0.2227, decode.cascade_2.acc_seg: 77.9211, loss: 1.1449
2021-08-27 14:12:50,166 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 14:12:50,183 - mmseg - INFO - Iter [7000/80000]	lr: 9.217e-03, eta: 8:10:14, time: 0.225, data_time: 0.057, memory: 18549, decode.final.loss_seg: 0.5241, decode.final.acc_seg: 77.1726, decode.4x.loss_seg: 0.2096, decode.4x.acc_seg: 77.1726, decode.cascade_1.loss_seg: 0.2162, decode.cascade_1.acc_seg: 76.8457, decode.cascade_2.loss_seg: 0.2259, decode.cascade_2.acc_seg: 76.1774, loss: 1.1758
2021-08-27 14:13:05,006 - mmseg - INFO - Iter [7050/80000]	lr: 9.211e-03, eta: 8:08:59, time: 0.296, data_time: 0.073, memory: 18549, decode.final.loss_seg: 0.4431, decode.final.acc_seg: 79.8234, decode.4x.loss_seg: 0.1772, decode.4x.acc_seg: 79.8234, decode.cascade_1.loss_seg: 0.1855, decode.cascade_1.acc_seg: 79.3832, decode.cascade_2.loss_seg: 0.1968, decode.cascade_2.acc_seg: 78.6453, loss: 1.0027
2021-08-27 14:13:17,167 - mmseg - INFO - Iter [7100/80000]	lr: 9.206e-03, eta: 8:07:17, time: 0.243, data_time: 0.051, memory: 18549, decode.final.loss_seg: 0.5089, decode.final.acc_seg: 78.8011, decode.4x.loss_seg: 0.2036, decode.4x.acc_seg: 78.8011, decode.cascade_1.loss_seg: 0.2104, decode.cascade_1.acc_seg: 78.3762, decode.cascade_2.loss_seg: 0.2208, decode.cascade_2.acc_seg: 77.6992, loss: 1.1437
2021-08-27 14:13:31,361 - mmseg - INFO - Iter [7150/80000]	lr: 9.200e-03, eta: 8:05:57, time: 0.283, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.5255, decode.final.acc_seg: 77.0457, decode.4x.loss_seg: 0.2102, decode.4x.acc_seg: 77.0457, decode.cascade_1.loss_seg: 0.2165, decode.cascade_1.acc_seg: 76.6872, decode.cascade_2.loss_seg: 0.2252, decode.cascade_2.acc_seg: 76.2285, loss: 1.1774
2021-08-27 14:13:44,389 - mmseg - INFO - Iter [7200/80000]	lr: 9.194e-03, eta: 8:04:27, time: 0.262, data_time: 0.022, memory: 18549, decode.final.loss_seg: 0.5241, decode.final.acc_seg: 77.3418, decode.4x.loss_seg: 0.2096, decode.4x.acc_seg: 77.3418, decode.cascade_1.loss_seg: 0.2166, decode.cascade_1.acc_seg: 76.8907, decode.cascade_2.loss_seg: 0.2268, decode.cascade_2.acc_seg: 76.2662, loss: 1.1770
2021-08-27 14:13:58,326 - mmseg - INFO - Iter [7250/80000]	lr: 9.189e-03, eta: 8:03:07, time: 0.278, data_time: 0.043, memory: 18549, decode.final.loss_seg: 0.5007, decode.final.acc_seg: 79.2124, decode.4x.loss_seg: 0.2003, decode.4x.acc_seg: 79.2124, decode.cascade_1.loss_seg: 0.2082, decode.cascade_1.acc_seg: 78.7742, decode.cascade_2.loss_seg: 0.2178, decode.cascade_2.acc_seg: 78.1688, loss: 1.1270
2021-08-27 14:14:26,698 - mmseg - INFO - Iter [7300/80000]	lr: 9.183e-03, eta: 8:04:11, time: 0.568, data_time: 0.070, memory: 18549, decode.final.loss_seg: 0.4592, decode.final.acc_seg: 80.1519, decode.4x.loss_seg: 0.1837, decode.4x.acc_seg: 80.1519, decode.cascade_1.loss_seg: 0.1922, decode.cascade_1.acc_seg: 79.5995, decode.cascade_2.loss_seg: 0.2026, decode.cascade_2.acc_seg: 78.9722, loss: 1.0378
2021-08-27 14:14:41,518 - mmseg - INFO - Iter [7350/80000]	lr: 9.178e-03, eta: 8:03:00, time: 0.296, data_time: 0.009, memory: 18549, decode.final.loss_seg: 0.4911, decode.final.acc_seg: 78.9479, decode.4x.loss_seg: 0.1964, decode.4x.acc_seg: 78.9479, decode.cascade_1.loss_seg: 0.2038, decode.cascade_1.acc_seg: 78.5168, decode.cascade_2.loss_seg: 0.2143, decode.cascade_2.acc_seg: 77.9085, loss: 1.1056
2021-08-27 14:14:53,403 - mmseg - INFO - Iter [7400/80000]	lr: 9.172e-03, eta: 8:01:21, time: 0.237, data_time: 0.020, memory: 18549, decode.final.loss_seg: 0.4984, decode.final.acc_seg: 79.4314, decode.4x.loss_seg: 0.1994, decode.4x.acc_seg: 79.4314, decode.cascade_1.loss_seg: 0.2064, decode.cascade_1.acc_seg: 79.1141, decode.cascade_2.loss_seg: 0.2162, decode.cascade_2.acc_seg: 78.4127, loss: 1.1204
2021-08-27 14:15:12,628 - mmseg - INFO - Iter [7450/80000]	lr: 9.166e-03, eta: 8:00:54, time: 0.385, data_time: 0.035, memory: 18549, decode.final.loss_seg: 0.5231, decode.final.acc_seg: 77.9575, decode.4x.loss_seg: 0.2093, decode.4x.acc_seg: 77.9575, decode.cascade_1.loss_seg: 0.2163, decode.cascade_1.acc_seg: 77.5212, decode.cascade_2.loss_seg: 0.2257, decode.cascade_2.acc_seg: 77.0128, loss: 1.1744
2021-08-27 14:15:26,999 - mmseg - INFO - Iter [7500/80000]	lr: 9.161e-03, eta: 7:59:41, time: 0.288, data_time: 0.021, memory: 18549, decode.final.loss_seg: 0.4659, decode.final.acc_seg: 79.7380, decode.4x.loss_seg: 0.1864, decode.4x.acc_seg: 79.7380, decode.cascade_1.loss_seg: 0.1922, decode.cascade_1.acc_seg: 79.4597, decode.cascade_2.loss_seg: 0.2015, decode.cascade_2.acc_seg: 78.8560, loss: 1.0460
2021-08-27 14:15:40,255 - mmseg - INFO - Iter [7550/80000]	lr: 9.155e-03, eta: 7:58:18, time: 0.264, data_time: 0.024, memory: 18549, decode.final.loss_seg: 0.5145, decode.final.acc_seg: 78.0137, decode.4x.loss_seg: 0.2058, decode.4x.acc_seg: 78.0137, decode.cascade_1.loss_seg: 0.2116, decode.cascade_1.acc_seg: 77.6612, decode.cascade_2.loss_seg: 0.2211, decode.cascade_2.acc_seg: 77.0461, loss: 1.1529
2021-08-27 14:16:01,280 - mmseg - INFO - Iter [7600/80000]	lr: 9.149e-03, eta: 7:58:09, time: 0.420, data_time: 0.011, memory: 18549, decode.final.loss_seg: 0.5027, decode.final.acc_seg: 78.3792, decode.4x.loss_seg: 0.2011, decode.4x.acc_seg: 78.3792, decode.cascade_1.loss_seg: 0.2081, decode.cascade_1.acc_seg: 78.0648, decode.cascade_2.loss_seg: 0.2182, decode.cascade_2.acc_seg: 77.4434, loss: 1.1301
2021-08-27 14:16:14,965 - mmseg - INFO - Iter [7650/80000]	lr: 9.144e-03, eta: 7:56:52, time: 0.275, data_time: 0.047, memory: 18549, decode.final.loss_seg: 0.4816, decode.final.acc_seg: 79.9690, decode.4x.loss_seg: 0.1927, decode.4x.acc_seg: 79.9690, decode.cascade_1.loss_seg: 0.1996, decode.cascade_1.acc_seg: 79.6052, decode.cascade_2.loss_seg: 0.2104, decode.cascade_2.acc_seg: 78.8621, loss: 1.0843
2021-08-27 14:16:30,031 - mmseg - INFO - Iter [7700/80000]	lr: 9.138e-03, eta: 7:55:48, time: 0.302, data_time: 0.027, memory: 18549, decode.final.loss_seg: 0.5094, decode.final.acc_seg: 78.6763, decode.4x.loss_seg: 0.2038, decode.4x.acc_seg: 78.6763, decode.cascade_1.loss_seg: 0.2118, decode.cascade_1.acc_seg: 78.1601, decode.cascade_2.loss_seg: 0.2223, decode.cascade_2.acc_seg: 77.4435, loss: 1.1473
2021-08-27 14:16:43,353 - mmseg - INFO - Iter [7750/80000]	lr: 9.133e-03, eta: 7:54:23, time: 0.254, data_time: 0.006, memory: 18549, decode.final.loss_seg: 0.4867, decode.final.acc_seg: 78.9720, decode.4x.loss_seg: 0.1947, decode.4x.acc_seg: 78.9720, decode.cascade_1.loss_seg: 0.2023, decode.cascade_1.acc_seg: 78.6212, decode.cascade_2.loss_seg: 0.2125, decode.cascade_2.acc_seg: 78.0364, loss: 1.0963
2021-08-27 14:16:58,507 - mmseg - INFO - Iter [7800/80000]	lr: 9.127e-03, eta: 7:53:27, time: 0.316, data_time: 0.022, memory: 18549, decode.final.loss_seg: 0.5266, decode.final.acc_seg: 77.7001, decode.4x.loss_seg: 0.2106, decode.4x.acc_seg: 77.7001, decode.cascade_1.loss_seg: 0.2173, decode.cascade_1.acc_seg: 77.3119, decode.cascade_2.loss_seg: 0.2265, decode.cascade_2.acc_seg: 76.7447, loss: 1.1810
2021-08-27 14:17:18,888 - mmseg - INFO - Iter [7850/80000]	lr: 9.121e-03, eta: 7:53:13, time: 0.405, data_time: 0.062, memory: 18549, decode.final.loss_seg: 0.4562, decode.final.acc_seg: 79.1673, decode.4x.loss_seg: 0.1825, decode.4x.acc_seg: 79.1673, decode.cascade_1.loss_seg: 0.1907, decode.cascade_1.acc_seg: 78.7848, decode.cascade_2.loss_seg: 0.2013, decode.cascade_2.acc_seg: 78.1634, loss: 1.0307
2021-08-27 14:17:39,119 - mmseg - INFO - Iter [7900/80000]	lr: 9.116e-03, eta: 7:52:58, time: 0.404, data_time: 0.013, memory: 18549, decode.final.loss_seg: 0.5078, decode.final.acc_seg: 78.5785, decode.4x.loss_seg: 0.2031, decode.4x.acc_seg: 78.5785, decode.cascade_1.loss_seg: 0.2112, decode.cascade_1.acc_seg: 78.1020, decode.cascade_2.loss_seg: 0.2206, decode.cascade_2.acc_seg: 77.4546, loss: 1.1428
2021-08-27 14:17:53,143 - mmseg - INFO - Iter [7950/80000]	lr: 9.110e-03, eta: 7:51:47, time: 0.280, data_time: 0.024, memory: 18549, decode.final.loss_seg: 0.5015, decode.final.acc_seg: 78.9678, decode.4x.loss_seg: 0.2006, decode.4x.acc_seg: 78.9678, decode.cascade_1.loss_seg: 0.2105, decode.cascade_1.acc_seg: 78.3804, decode.cascade_2.loss_seg: 0.2207, decode.cascade_2.acc_seg: 77.7513, loss: 1.1333
2021-08-27 14:18:04,452 - mmseg - INFO - Saving checkpoint at 8000 iterations
2021-08-27 14:18:11,583 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 14:18:11,583 - mmseg - INFO - Iter [8000/80000]	lr: 9.104e-03, eta: 7:51:16, time: 0.368, data_time: 0.016, memory: 18549, decode.final.loss_seg: 0.4957, decode.final.acc_seg: 77.9546, decode.4x.loss_seg: 0.1983, decode.4x.acc_seg: 77.9546, decode.cascade_1.loss_seg: 0.2076, decode.cascade_1.acc_seg: 77.4417, decode.cascade_2.loss_seg: 0.2172, decode.cascade_2.acc_seg: 76.8712, loss: 1.1188
2021-08-27 14:25:16,887 - mmseg - INFO - per class results:
2021-08-27 14:25:16,932 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 83.16 | 86.95 |
|    sidewalk   | 42.18 | 59.02 |
|    building   | 63.95 | 70.53 |
|      wall     |  5.18 |  5.71 |
|     fence     | 17.39 | 19.57 |
|      pole     | 20.13 | 27.33 |
| traffic light |  2.1  |  2.18 |
|  traffic sign | 22.48 | 27.13 |
|   vegetation  | 74.55 | 94.62 |
|    terrain    | 20.69 | 21.58 |
|      sky      | 74.86 | 78.15 |
|     person    | 19.25 | 79.98 |
|     rider     |  0.39 |  0.4  |
|      car      | 51.03 | 89.47 |
|     truck     |  1.25 |  1.27 |
|      bus      |  2.83 |  3.3  |
|     train     |  0.22 |  1.1  |
|   motorcycle  |  3.6  |  5.06 |
|    bicycle    | 29.27 | 34.21 |
+---------------+-------+-------+
2021-08-27 14:25:16,942 - mmseg - INFO - Summary:
2021-08-27 14:25:16,942 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 78.5 | 28.13 | 37.24 |
+------+-------+-------+
2021-08-27 14:25:16,944 - mmseg - INFO - Exp name: icnet_r50-d8_512x1024_80k_cityscapes.py
2021-08-27 14:25:16,944 - mmseg - INFO - Iter(val) [125]	aAcc: 0.7850, mIoU: 0.2813, mAcc: 0.3724, IoU.road: 0.8316, IoU.sidewalk: 0.4218, IoU.building: 0.6395, IoU.wall: 0.0518, IoU.fence: 0.1739, IoU.pole: 0.2013, IoU.traffic light: 0.0210, IoU.traffic sign: 0.2248, IoU.vegetation: 0.7455, IoU.terrain: 0.2069, IoU.sky: 0.7486, IoU.person: 0.1925, IoU.rider: 0.0039, IoU.car: 0.5103, IoU.truck: 0.0125, IoU.bus: 0.0283, IoU.train: 0.0022, IoU.motorcycle: 0.0360, IoU.bicycle: 0.2927, Acc.road: 0.8695, Acc.sidewalk: 0.5902, Acc.building: 0.7053, Acc.wall: 0.0571, Acc.fence: 0.1957, Acc.pole: 0.2733, Acc.traffic light: 0.0218, Acc.traffic sign: 0.2713, Acc.vegetation: 0.9462, Acc.terrain: 0.2158, Acc.sky: 0.7815, Acc.person: 0.7998, Acc.rider: 0.0040, Acc.car: 0.8947, Acc.truck: 0.0127, Acc.bus: 0.0330, Acc.train: 0.0110, Acc.motorcycle: 0.0506, Acc.bicycle: 0.3421
